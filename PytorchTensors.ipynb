{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import torch","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.set_default_dtype(torch.float64)\n# only floating type can be set as dytpe\n# pytorch has 8 CPU type tensors, 8 GPU type tensors\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.get_default_dtype()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"torch.float64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_arr= torch.Tensor(([1,2,3],[4,5,6]))\ntensor_arr","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"tensor([[1., 2., 3.],\n        [4., 5., 6.]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.is_tensor(tensor_arr)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.numel(tensor_arr)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"6"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_uninitialised = torch.Tensor(2, 2)\n# unitntialised, - give memmory but not instatiate\ntensor_uninitialised \n# displays random values","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"tensor([[6.9011e-310, 6.9011e-310],\n        [1.5810e-322, 3.1620e-322]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_initialised = torch.rand(2, 2)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_initialised \n# quick to initalise params of wts of model","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"tensor([[0.5522, 0.3736],\n        [0.7207, 0.7056]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_int = torch.Tensor([5,3]).type(torch.IntTensor)\n# for making tensors on CPU, for GPU alternative use torch.cuda.IntTensor\ntensor_int","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"tensor([5, 3], dtype=torch.int32)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_short = torch.ShortTensor([1.0, 2.0, 3.0])\ntensor_short","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"tensor([1, 2, 3], dtype=torch.int16)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_float= torch.tensor([1.0, 2.0, 3.0]).type(torch.half)\ntensor_float\n# uses half memory of float32","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"tensor([1., 2., 3.], dtype=torch.float16)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensor_fill = torch.full((2,6),fill_value=10)\ntensor_fill","execution_count":17,"outputs":[{"output_type":"stream","text":"/pytorch/aten/src/ATen/native/TensorFactories.cpp:361: UserWarning: Deprecation warning: In a future PyTorch release torch.full will no longer return tensors of floating dtype by default. Instead, a bool fill_value will return a tensor of torch.bool dtype, and an integral fill_value will return a tensor of torch.long dtype. Set the optional `dtype` or `out` arguments to suppress this warning.\n","name":"stderr"},{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"tensor([[10., 10., 10., 10., 10., 10.],\n        [10., 10., 10., 10., 10., 10.]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# torch.ones()\n# torch.zeroes_like(tensor) - copies shape, fills with 0\n# torch.eye() fills diagonal ele with 1\n# torch.nonzero() displays non zero\n# torch.sparse_coo_tensor ( indices - sparse contains data)\n# tensor.data","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}